## 什么是上下文切换

Linux 是一个多任务操作系统, 进程在竞争 CPU 的时候并没有真正的运行, 为什么系统负载还是会升高呢.

Linux 在运行每个任务前都需要进行这样的操作, 保存当前任务的上下文环境(寄存器,程序计数器),然后加载下一个任务的上下文环境到寄存器和程序计数器等,跳转到程序计数器指向的指令位置,进而开始执行任务, 这就是上下文切换

上下文切换分为多种, 根据任务的不同,可以分为 `进程上下文`, `线程上下文`, `中断上下文`. 

### 进程上下文

一个进程运行中会处于 2 种状态分别是 **用户空间**和**内核空间**, 从用户态到内核态的转变需要通过系统调用(system call).

系统调用是就会发生上下文切换, 当系统调用发生时,上下文切换流程如下:

**用户态 --> 内核态**

1. 保存当前 CPU 寄存器中用户态的指令位置
2. 更新寄存器为内核态指令的新位置
3. 最后跳转到内核态执行内核任务

**内核态 --> 用户态**

1. CPU 寄存器更新为用户态的指令
2. 切换到用户空间继续执行

在系统调用中 CPU 不会涉及到虚拟内存 等进程用户态的资, 也不会切换进程, 进程上下文指的是不同进程间的切换,系统调用又称之为**特权模式**,但是在系统调用时上下文切换时无法避免的。

那进程上下文切换时系统调用有什么联系? 进程是由内核管理的,进程的上下文包括 虚拟内存、栈、全局变量、等用户空间的资源, 同时还包括内核堆栈、寄存器、等内核空间的状态. 进程的切换只能在内核态完成.

因此进程的上下文切换就比系统调用时多了一步, 保存当前进程的用户、内核态资源, 加载其他进程的上下文, 刷新进程的虚拟内存和用户栈, 内核切换并运行进程.

#### 什么条件会导致进程的切换呢

当进程切换时也需要切换上下文, 那什么时候会导致进程的切换呢？

Linux 为每一个 CPU 维护了一个就绪队列,将活跃进程(正在运行进程,和等待CPU运行进程)按照优先级和等待 CPU 的时间排序, 然后选择最需要 CPU 的进程来运行。那进程在什么情况下会被调度在 CPU 上运行?

1. 为保证所有进程公平调度, CPU 时间被划分为多段时间片轮流分配给各进程, 当某个进程的时间片耗尽 就会被系统挂起, 切换到其他进程.
2. 进程在系统资源不足的时候, 要等到资源满足后才可以运行, 这个时候进程也会被挂起,并调度其他进程运行
3. 进程自己通过 sleep 方法将自己挂起,也会触发调度
4. 当出现优先级更高的进程
5. 发生硬件中断,硬件中断的优先级时最高的

### 线程上下文切换

进程和线程最大的区别在于, **线程是资源调度的基本单位, 而进程是资源拥有的基本单位**, 也就是说进程负责资源的管理 为线程提供了虚拟内存、全局变量等资源,而线程负责任务的执行

- 当进程只有一个线程时,可以任务线程就等于进程.
- 当进程有多个线程时,此时线程共享进程的资源,在进行上下文切换并不需要保存.
- 线程也拥有独立数据,比如栈和寄存器等,在线程切换时需要保存这些内容.

线程的上下文切换分为 2 种情况:

1. 单个线程的切换, 这里就相当于进程的上下文切换
2. 同一个进程下的线程切换, 此时共享资源保存不变,只需要切换线程的私有数据, 也就是寄存器等.

### 中断上下文切换

为了快速响应硬件的事件, **中断的处理会打断当前进程的调度和执行**,转而执行中断处理程序来响应设备事件, 而在打断其他进程时,就需要保存当前进程的状态,中断程序结束后,恢复原本的状态运行.

中断程序并不涉及到用户态的资源,所以不需要保存,只需要保存当前进程内核态的资源,然后加载中断程序的需要的环境,也就是 CPU 寄存器、内核堆栈、硬件中断参数等等。

### vmstat

vmstat 用于分析系统总体的内存使用情况, 也可以用于分析 CPU 上下文切换的次数.

```bash
# 每隔 5 秒钟输出一次数据
$ vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 2388744  24204 324360    0    0   986    81  187  253  2  4 94  1  0
 0  0      0 2388620  24204 324544    0    0     0     0  169  223  0  0 100  0  0
 0  0      0 2388620  24212 324544    0    0     0     5  164  219  0  0 100  0  0
 ```

相关 CPU 的指标需要关注这 4 列内容:

1. cs(context switch): 每秒上下文切换的次数
2. in(interrupt): 每秒的中断的次数
3. r(Running or Runnable): CPU 上的就绪队列的长度,也就是正在运行和等待 CPU 的进程数
4. b(blocked): 则是处于不可中断的睡眠状态的进程数量

### pidstat

vmstat 主要是参考系统整体的性能指标, 而 pidstat `-w` 可以查看每个进程上下文切换的情况

```bash
# 每隔 5 秒输出一次
$ pidstat -w 5
Linux 5.4.0-100-generic (u-dev01)       03/12/2022      _x86_64_        (4 CPU)

04:05:08 PM   UID       PID   cswch/s nvcswch/s  Command
04:05:08 PM     0         1      1.26      0.54  systemd
04:05:08 PM     0         2      0.28      0.00  kthreadd
# 省略其他
```

这里重点需要关注 2 个指标：

1. cswch: 表示每秒自愿上下文切换的次数。
2. nvcswch: 表示每秒非自愿上下文切换的次数

所谓**自愿上下文切换**,是指进程无法获取所需资源，导致的上下文切换。比如说, I/O、内存等系统资源不足时，就会发生自愿上下文切换
而非**自愿上下文切换**,则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

### 上线文切换次数指标

在实际系统或进程上,上下文切换频率多少次才算正常呢? 

通过 sysbench 来模拟系统多线程调度切换的情况.他是一个多线程的基准测试工具, 一般来评估数据库负载情况, 这次就给他当成异常进程来看,主要来模拟上下文切换次数过多的问题.

```bash
# 以 10 个线程运行,模拟多线程切换的问题
$ sysbench --threads=10 --max-time=300 threads run
```

vmstat 来观察上下文切换

```bash
$ vmstat 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 2233348  28008 458000    0    0     0     0  176  239  0  0 100  0  0
 9  0      0 2232332  28008 458000    0    0     0     0 34155 1036335 18 34 49  0  0
 9  0      0 2232332  28008 458000    0    0     0     0 59706 1682399 29 62  9  0  0
```

1. 可以看到 cs 增长到了百万级别,同时 r 队列已经到了 9 远超过了系统 4 核 cpu, 所以大量的进程会对 CPU 竞争.
2. 而 us 和 sy 加起来已经到达了 100, 主要的时间耗费在了内核中。
3. in 说明中断次数也就上升到了 5 万左右, 说明中断处理也是个潜在的问题.

综合这几个指标,我们可以知道，系统的就绪队列过长,也就是正在运行和等待 CPU 的进程数量过多, 导致了大量的上下文切换, 而上下文切换又导致了系统 CPU 的占用率升高.


pidstat 来看一下 CPU 和进程上下文切换的情况, pidstat 的默认是对进程做输出,并不会对线程输出. `-t` 列出线程指标

```bash
# 每隔 5 输出一组数据
# -w 表示输出进程上下文切换指标
# -t 表示输出线程上下文切换指标
# -u 表示输出 CPU 指标
$ pidstat -wt -u 5
Average:      UID      TGID       TID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0      2132         -  115.46  234.78    0.00    0.00  350.24     -  sysbench
Average:        0         -      2133   10.14   24.15    0.00   38.65   34.30     -  |__sysbench
Average:        0         -      2134   11.11   22.71    0.00   39.13   33.82     -  |__sysbench
Average:        0         -      2135   13.04   23.19    0.00   24.64   36.23     -  |__sysbench
Average:        0         -      2136   11.11   23.67    0.00   39.61   34.78     -  |__sysbench
Average:        0         -      2137   11.11   25.12    0.00   31.40   36.23     -  |__sysbench
Average:        0         -      2138   12.56   21.74    0.00   41.06   34.30     -  |__sysbench
Average:        0         -      2139   11.11   25.12    0.00   28.99   36.23     -  |__sysbench
Average:        0         -      2140   10.63   22.71    0.00   31.40   33.33     -  |__sysbench
Average:        0         -      2141   14.01   20.29    0.00   32.85   34.30     -  |__sysbench
Average:        0         -      2142   10.63   25.60    0.00   31.88   36.23     -  |__sysbench

Average:      UID      TGID       TID   cswch/s nvcswch/s  Command
Average:        0      1745         -      5.80      0.00  kworker/u256:1-events_power_efficient
Average:        0         -      1745      5.80      0.00  |__kworker/u256:1-events_power_efficient
Average:        0         -      2133  10427.05 115406.76  |__sysbench
Average:        0         -      2134   9108.70 118374.88  |__sysbench
Average:        0         -      2135  10079.71  96862.80  |__sysbench
Average:        0         -      2136   9268.12 119038.16  |__sysbench
Average:        0         -      2137   8407.73  92128.02  |__sysbench
Average:        0         -      2138   7694.69 118516.43  |__sysbench
Average:        0         -      2139   8710.63  88769.08  |__sysbench
Average:        0         -      2140   9909.18 102478.74  |__sysbench
Average:        0         -      2141  11867.15 112787.92  |__sysbench
Average:        0         -      2142   8814.01  95544.44  |__sysbench
```

通过上面可以查看到 CPU 上升确实是由于 sysbench 导致的, 每个线程中的上线文切换也一目了然


### 系统中断情况查看

在前面 vmstat 发现 in 中断比较高,这个是由于什么导致的呢, 中断是发生在内核态的,pidstat 只能捕获用户态的相关指标, 可以通过 **/proc/interrupts** 这个文件提供了一个只读的中断情况. 

```bash
# -d 参数表示高亮显示变化的区域
$ watch -d cat /proc/interrupts
 CPU0 CPU1
...
RES: 2450431 5279697 Rescheduling interrupts
...
```

可以看到 RES 的值变化的很快, 这个表示的是**重调度中断** 这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行.也就是说明 中断过高是由于多个进程来回调度的问题。跟前面的结果是一致的。

## 总结

1. CPU 的上下文切换是保证 Linux 任务正常运行调度的核心功能.
2. 过多的上下文切换,CPU 会将大量的时间耗费在 寄存器、内核栈以及虚拟内存等数据的保存和恢复上, 从而缩短了进程真正运行的时间,导致系统整体性能下降.
3. 上下文切换次数出现量级的增长时,就很可能出现了问题.
4. 自愿上下文切换次数过多说明进程都在等待资源,有可能发生了 i/o 等其他问题.
5. 非自愿上下文切换过多 说明进程都在被强制调度, 也就是都在争抢 cpu 说明 cpu 成为了系统瓶颈。
6. 中断次数变多,说明cpu被中断处理程序占用, 需要通过 /proc/interrupts 文件来分析具体的中断类型.