## 背景

在线上环境中偶然发现机器中存在了 1w+ 的僵尸进程, 初步排除其父进程发现是 Docker 容器中产生的.

### 僵尸进程是如何产生的

僵尸进程是指一个已经死亡的进程(exit(),或者强制退出), 这时候子进程等待其父进程回收自己的资源, 如果父进程没有(wait/waitpid)回收机制,就会造成僵尸进程的产生, 僵尸进程不能被杀死，因为它们已经死亡，只等待它们的父进程回收它们.

还有一种叫做 **孤儿进程** 这种进程通常不会有害, 是指其父进程提前退出了,其子进程就会被 init 进程所管理.由 init 进程来回收其资源。当进程的父进程 id 变为 1 的时候，这个进程也有了专门定义的称谓，叫做孤儿进程, 通常这种情况会在容器内部.

### init 进程

linux 系统启动后，第一个被创建的用户态进程就是init进程。

1. 负责执行系统初始化脚本，创建一系列的进程(它们都是init进程的子孙);
2. 在一个死循环中等待其子进程的退出事件，并调用 waitid 系统调用来完成“收尸”工作
3. init进程不会被暂停、也不会被杀死(这是由内核来保证的)

#### 为什么 init 进程不会被 kill 掉

首先当进程对 init 进程发送 kill 的时候, kill 需要通过触发 kill() 系统调用来向进程发送信号, 这个系统调用对应的内核函数 sys_kill(), 而在函数执行的时候,会触发一个判断函数 sig_tasks_ignored() 来判断是否忽略这个信号.

Linux 内核针对每个 Nnamespace 里的 init 进程，把只有 default handler 的信号都给忽略了.

如何查看进程是否注册了 handler, 可以通过 proc/1/status | grep -i sigcgt 来查看, 通过转换为二进制,从左往右 1 开始数.对应每个信号的编号.

```bash
$ docker exec myapp_01 cat /proc/1/status |grep -i sigcgt
SigCgt: 0000000018016a07

0000000018016a07 = 11000000000010110101000000111
                                 |
                                 |-------> 对应15信号, 也就是说可以 kill 1, 但是忽略了 kill -9 1

### 字段解释:
$ cat /proc/1/status
通过进程进程的 PID，然后查看/proc/$PID/status. 它包含描述哪些信号被阻止 (SigBlk)忽略 (SigIgn) 或捕获 (SigCgt) 的行。
...
SigBlk: 0000000000000000
SigIgn: fffffffe57f0d8fc
SigCgt: 00000000280b2603
...
```

### 那为什么 Docker 会发生大量的僵尸进程

在 docker 中的 init 进程通常是我们运行的主进程, 当 Docker 内部的主进程产生了一些子进程的时候, 当子进程执行任务结束以后, 会通知父进程回收, 但是父进程没有收回子进程的能力, 因为就会造成僵尸进程. 所以这时候矛头指向了父进程。

1. 定位僵尸进程的 PPID

```bash
ps -elf |grep -- Z
F S UID         PID   PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
0 Z 999        6823  17754  0  80   0 -     0 -      Mar20 ?        00:00:00 [sh] <defunct>
0 Z 999       11567  17754  0  80   0 -     0 -      Mar20 ?        00:00:00 [sh] <defunct>
0 Z 999       15044  17754  0  80   0 -     0 -      Mar20 ?        00:00:00 [sh] <defunct>
4 Z 999       18580  17754  0  80   0 -     0 -      Mar18 ?        00:00:00 [sh] <defunct>
0 Z 999       18884  17754  0  80   0 -     0 -      Mar18 ?        00:00:00 [sh] <defunct>
0 Z 999       39387  17754  0  80   0 -     0 -      Mar22 ?        00:00:00 [sh] <defunct>
0 Z 999       39435  17754  0  80   0 -     0 -      Mar22 ?        00:00:00 [sh] <defunct>
0 Z 999       66472  17754  0  80   0 -     0 -      Mar21 ?        00:00:00 [sh] <defunct>
```

2. 可以看到在宿主机上的僵尸进程的 PPID 是 17754, 这时候在定位其中父进程。

```bash
# 通过 pstree -aps <PID> 可以获取进程关系
$ pstree -aps 17754 | head -n 10
init,1
  `-containerd,117425
      `-containerd-shim,17734 -namespace moby -workdir...
          `-skernel-worker,17754 /usr/local/bin/skernel-worker
          # 忽略下面的僵尸进程 和敏感信息
```

3. 通过上面的调用关系可以发现, 僵尸进程的父进程是 11754 这个进程, 这个进程是由 Docker 内部产生的, 于是进入内部进行查看.

```bash
$ docker exec -it 181faeef0eedf5ea7eb2892 bash

$ ps -elf
F S UID         PID   PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S skernel       1      0  2  80   0 - 524783 do_epo Mar18 ?       03:53:56 /usr/bin/python3.8 /usr/local/bin/skernel-worker
4 Z skernel      92      1  0  80   0 -     0 -      Mar18 ?        00:00:00 [sh] <defunct>
0 Z skernel     275      1  0  80   0 -     0 -      Mar18 ?        00:00:00 [sh] <defunct>
0 Z skernel  102476      1  0  80   0 -     0 -      Mar22 ?        00:00:00 [sh] <defunct>
0 Z skernel  102514      1  0  80   0 -     0 -      Mar22 ?        00:00:00 [sh] <defunct>
0 Z skernel  114455      1  0  80   0 -     0 -      10:54 ?        00:00:00 [sh] <defunct>
0 Z skernel  114526      1  0  80   0 -     0 -      10:54 ?        00:00:00 [sh] <defunct>
0 Z skernel  134597      1  0  80   0 -     0 -      Mar22 ?        00:00:00 [sh] <defunct>
```

4. 这里看到的现象是在容器内部的 pid namespace 中 子进程已经成为了 init 进程收养的孤儿进程, 这时候应该由 init 进程来回收进程资源, 但是这里的 init 由于不是传统的 init 进程,是容器内部工作的主进程, 所以不具备回收的机制. 造成大量僵尸进程的现象.

### 解决方案

有两个解决办法可以让docker的init进程能够处理孤儿进程。

-  启动docker容器时，指定init进程为bash，由bash进程对孤儿进程的资源进行回收, **这里不推荐使用** 因为 bash 不会做信号转发，当执行 docker stop 的时候, 只会通知 bash 进程也就是容器内的 init 进程退出, 并不会通知其子进程。

- 增加专门的 init 进程，比如 tini。

1. docker 中使用 tini 作为主进程, 使用 `--init`

```bash
$ docker run -d --name test_init --init nginx
```

2. docker-compose 中使用 tini 作为主进程

```bash
# 在容器中运行一个 init 进程并转发信号。设置为 true 为服务使能这个特性。
version: "3.8"
services:
  web:
    image: alpine:latest
    init: true
```

## 扩展

那在 Docker 中存在此类大量僵尸进程的问题, 在 K8s 中会不会也存在.

我们知道在 K8s 中最小的调度单位是 Pod, 而在每一个 Pod 中都启用一个辅助容器叫 `/Pause`,他主要的工作是作为 Pod 内容器的父容器.

- 在 Pod 中它作为共享 Linux Namespace（Network、UTS 等）的基础；
- 启用 PID Namespace 共享，它为每个 Pod 提供 1 号进程，并收集 Pod 内的僵尸进程。

### 这里举个栗子验证一下:

1. 创建一个 Pod

```bash
apiVersion: v1  # group/version
kind: Pod       # 资源类别
metadata:       # 元数据
  name: pod-demo      # Pod name
  namespace: default  # namespace
  labels:             # lables list 或者 map 类型
    app: myapp
spec:           # 定义用户期望状态
  containers:   # 定义 Pod 容器
  - name: myapp   # 容器名
    image: ubuntu
    imagePullPolicy: IfNotPresent # images 获取策略, Always, Never,IfNotPresent
    command: ["tail","-f","/dev/null"]

$ kubectl create -f zombie_pod.yaml
```

2. 查看 Pod 内的 init 进程.

```bash
root@kubernetes-master01:~# kubectl exec -it pod-demo bash
root@pod-demo:/# ps -elf
F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S root           1       0  0  80   0 -   636 hrtime 06:10 ?        00:00:00 tail -f /dev/null
4 S root           7       0  0  80   0 -  1060 do_wai 06:13 pts/0    00:00:00 bash
4 R root          16       7  0  80   0 -  1473 -      06:14 pts/0    00:00:00 ps -elf
```

2. 这里并不符合预期，为什么主进程的 PID 为 1 呢，不是应该是 Pasue 为主进程吗. 模拟一个僵尸进程看看会不会回收掉.

```bash
root@pod-demo:/# sleep 400 &
[1] 17
root@pod-demo:/# ps -elf
F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S root           1       0  0  80   0 -   636 hrtime 06:10 ?        00:00:00 tail -f /dev/null
4 S root           7       0  0  80   0 -  1060 do_wai 06:13 pts/0    00:00:00 bash
0 S root          17       7  0  80   0 -   627 hrtime 06:16 pts/0    00:00:00 sleep 400

# 可以看到 sleep 是 bash 的子进程, 当 bash 退出后, sleep 会不会被 init 进程回收. ctrl + c
```

3. 重新查看 sleep 进程

```bash
# 再次重新进入 Pod 内查看,可以看到依然出现了僵尸进程。因为 tail 命令并没有回收进程的能力
root@pod-demo:/# ps -elf
F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S root           1       0  0  80   0 -   636 hrtime 06:10 ?        00:00:00 tail -f /dev/null
0 S root          20       1  0  80   0 -   627 hrtime 06:18 ?        00:00:00 sleep 30
4 S root          21       0  0  80   0 -  1060 do_wai 06:18 pts/1    00:00:00 bash
0 R root          30      21  0  80   0 -  1473 -      06:18 pts/1    00:00:00 ps -elf
root@pod-demo:/#
root@pod-demo:/# ps -elf
F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S root           1       0  0  80   0 -   636 hrtime 06:10 ?        00:00:00 tail -f /dev/null
0 Z root          20       1  0  80   0 -     0 -      06:18 ?        00:00:00 [sleep] <defunct>
4 S root          21       0  0  80   0 -  1060 do_wai 06:18 pts/1    00:00:00 bash
0 R root          31      21  0  80   0 -  1473 -      06:19 pts/1    00:00:00 ps -elf
```

### K8s 解决方案

通过上面发现，Pause 并没有作为容器中的主进程, 这是为什么, 这是因为在 K8s 中默认父容器是不共享 Pid namespace 的. 因此造成了这个问题。 只需要让子容器共享父容器的 pidnamespce 即可解决。

修改 zombie_pod.yaml 文件

```bash
spec:           # 定义用户期望状态
  shareProcessNamespace: true    # 共享进程命名空间
  containers:   # 定义 Pod 容器
  - name: myapp   # 容器名
    image: ubuntu
    imagePullPolicy: IfNotPresent # images 获取策略, Always, Never,IfNotPresent
    command: ["tail","-f","/dev/null"]

$ kubectl delete -f zombie_pod.yaml
$ kubectl apply -f zombie_pod.yaml
```

查看其容器的主进程

```bash
root@kubernetes-master01:~# kubectl exec -it pod-demo bash
root@pod-demo:/# ps -elf
F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S 65535          1       0  0  80   0 -   241 -      06:28 ?        00:00:00 /pause
4 S root           8       0  0  80   0 -   636 hrtime 06:29 ?        00:00:00 tail -f /dev/null
4 S root          14       0  0  80   0 -  1060 do_wai 06:29 pts/0    00:00:00 bash
0 R root          23      14  0  80   0 -  1473 -      06:29 pts/0    00:00:00 ps -elf
```
